\Chapter{OPPORTUNISME ET ORDONNANCEMENT}\label{sec:Theme2}
Dans le contexte d'optimisation de boîte noire, chaque évaluation de la fonction objectif requiert un temps d'attente non-négligeable par l'utilisation de ressources informatiques; il est indispensable de veiller à ce que l'algorithme choisi soit conçu avec des spécificités réduisant le nombre d'appels à la boîte noire. Dans cette optique, les étapes de \POLL des algorithmes présentés précédemment sont revues.
\section{Stratégie Opportuniste}
Pour les algorithmes présentés à la section précédente, les analyses de convergence reposent sur une suite d'échecs à l'étape de \POLL, tandis que les étapes de \SEARCH sont d'avantage accessoires et simplement destinées à accélérer la convergence en pratique. Afin d'adapter les méthodes de recherche directe aux problèmes pouvant être traités comme des boîtes noires, il est primordial d'étudier chaque aspect pouvant entraîner une réduction d'évaluation de la fonction objectif dans la \POLL sans interférer avec ses propriétés. Ainsi, l'outil fourni est soutenu par une base théorique forte prouvant l'obtention d'une solution optimale~\cite{Torc97a,CoPr01a,AuDe2006,Kelley2011,KoLeTo03a} et est muni d'un processus soigneusement conçu pour éviter les évaluations couteuses. Les quelques définitions suivantes seront nécessaires à l'introduction de la stratégie principale qui reste à être formellement introduite.
\theoremstyle{definition}
\begin{definition}[Ensembles de recherche et de sonde]\label{def:3.1}
L'ensemble de recherche, désigné par $S^k$, est l'ensemble de points candidats pour l'étape de \SEARCH. L'ensemble de sonde, désigné $P^k$, est l'ensemble des points candidats pour l'étape de \POLL à l'itération $k$ d'un algorithme de recherche directe.
\end{definition} 
Par exemple, pour \CS, $S^k := \{\}$~\text{et}~$P^k :=\{x^k +\delta^ke_i ~\text{avec}~ i \in \{1,2,\dots,n\cup\N\}\}$. 
\begin{definition}[Diminution simple]
\label{def:3.2}Pour un algorithme de recherche directe, on dit qu'un candidat de $S^k$ entraîne une diminution simple si 
\begin{equation}
\label{eq:3.1}\exists~\tau~\in S^k~ \text{tel que}~ f(\tau) < f(x^k).
\end{equation}
Analoguement, on dit qu'un candidat dans $P^k$ entraîne une diminution suffisante si 
\begin{equation}
\label{eq:3.2}\exists~\tau~\in P^k ~\text{tel que} ~ f(\tau) < f(x^k).
\end{equation}
\end{definition}
La présence d'un candidat dans $P^k$ entraînant une diminution simple peut être un critère de succès pour une étape de \POLL. Ce n'est pas toujours le cas, tel que présenté précédemment dans \GSS, où le critère est de succès d'une \POLL requiert une diminution suffisante $\exists~\tau~\in P^k ~\text{tel que} ~ f(\tau) < f(x^k) + \rho$, où $\rho \geq 0$ est la différence minimale désirée entre les deux valeurs de la fonction objectif. Outre les diminutions simple et suffisante, on introduit un autre critère caractérisant un candidat.
\begin{definition}[Meilleure diminution]
	\label{def:3.3}Pour une étape de \POLL d'un algorithme de recherche directe, on dit qu'un candidat $\tau$ de $P^k$ entraîne la meilleure diminution de la fonction objective si 
	\begin{equation*}
	f(\tau) \leq f(p^k)~ \forall~ p^k \in P^k
	\end{equation*}
\end{definition}
Le cas traité ici est un l'obtention d'un optimum en utilisant un algorithme dans sa forme séquentielle. En pratique, il s'agit d'évaluer les points de façon séquentielle ou parallèle. Cependant, dans le cas d'optimisation de boîte noire, il est nécessaire de choisir si l'utilisation des ressources parallèles sont destinées à l'évaluation de la boîte noire, ou si elles sont dédiées à une version parallèle de l'algorithme~\cite{HoKoTo01a,AuDeLe08}. Il est intéressant de paralléliser un algorithme pour un ensemble de tâches indépendantes, par exemple dans l'optimisation de paramètres algorithmiques~\cite{AuDaOr13a}. Dans le cas où la boite noire est lourde en calculs et nécessite de grandes ressources en parallèle pour une évaluation unique, il est envisageable d'utiliser un algorithme dans sa version en séquentielle. L'utilisation d'un algorithme de recherche directe séquentiel signifie qu'au moment initial d'une étape de \POLL, $2n$ évaluations en série de la boîte noire sont possiblement à venir. Dans les algorithmes présentés, pour considérer la \POLL courante comme un succès, on n'exige pas la détermination d'un candidat entrainant la meilleure diminution au sens de la définition \ref{def:3.3}; elle exige la détermination d'un candidat apportant une diminution simple. Ainsi, pour le premier candidat satisfaisant Léquation (\ref{eq:3.2}), l'algorithme pourrait passer à l'étape suivante en considérant la présente comme un succès. Alternativement, on pourrait aussi continuer à évaluer la fonction objectif aux autres points de l'ensemble de sonde, de façon à identifier le candidat entraînant la meilleure diminution. Ces décisions algorithmiques sont le cœur de l'étude présente. 
\begin{definition}[Stratégie opportuniste (ou opportunisme)]
La stratégie opportuniste désigne l'arrêt prématuré de l'étape \SEARCH ou \POLL courante d'un algorithme de recherche directe dès la première obtention d'un point $\tau$ satisfaisant le critère de succès de l'algorithme, soit la diminution simple ou la diminution suffisante.
\end{definition}
En opposition à la stratégie opportuniste, on définit l'idée consistant à évaluer tous les points de l'ensemble $P^k$ ou $S^k$.
\begin{definition}[Sonde complète et recherche complète]
La sonde complète désigne l'évaluation de la fonction objectif à tous les points candidats de $P^k$ de l'étape de \POLL sans égard à l'identification encourue d'un candidat entrainant une diminution simple ou suffisante. 

La recherche complète désigne l'évaluation de la fonction objectif à tous les points candidats de $S^k$ de l'étape de \SEARCH sans égard à l'identification encourue d'un candidat entrainant une diminution simple ou suffisante. 
\end{definition}
Ces définitions concordent avec les mentions de l'opportunisme dans la littérature. Coope et Price~\cite{CoPr01a} sont les premiers à utiliser le terme d'opportunisme. De prime abord, ils identifient deux cadres de travail pour des algorithmes d'optimisation sans-contraintes dont les points sont limités à des maillages, soit les cadres A et B. Les deux cadres peuvent être résumés ainsi.
\begin{algorithm}[H]
	\caption{\textsf{Cadre algorithmique opportuniste(A) de Coope et Price}}
	\label{A}
	\begin{algorithmic}
	\STATE $f:\R^n\rightarrow \R$ la fonction objectif et $x^0$ le point de départ.
	\STATE \begin{tabularx}{440pt}{l X}1. & Déterminer un pas $\delta ^k$ et une base positive ordonnée $D^k:={d_1^k,d_2^k,\dots,d^k_l}$. Fixer $i \leftarrow 1$.\end{tabularx}
	\STATE \begin{tabularx}{440pt}{l X}2. & Déterminer une direction de descente $d_i^k\in D^k$ qui emmène une diminution simple de la fonction. Si une telle direction existe, mettre à jour la solution courante $x^k$. Sinon, essayer avec la prochaine direction dans la base positive ordonnée en incrémentant $i\leftarrow i+1$. Si aucun $i$ ne satisfait la condition, passer à l'étape 3.\end{tabularx}
	\STATE \begin{tabularx}{440pt}{l X}3. & Déterminer un ensemble de points finis avec une procédure arbitraire (\SEARCH). Si cette procédure produit une diminution simple de la fonction objective, mettre à jour la solution. Retour à 1.\end{tabularx}
	\end{algorithmic}
\end{algorithm}
\begin{algorithm}[H]
	\caption{\textsf{Cadre algorithmique non-opportuniste (B) de Coope et Price}}
	\label{A}
\begin{algorithmic}
		\STATE $f:\R^n\rightarrow \R$ la fonction objectif et $x^0$ Le point de départ 
		\STATE  \begin{tabularx}{440pt}{l X}
			1. & Déterminer un pas $\delta ^k$ et une base positive ordonnée $D^k$. $i \leftarrow 1$.
		\end{tabularx}
	\STATE \begin{tabularx}{440pt}{l X}
		2. & Déterminer la direction menant à la meilleure descente $d_i^k$ dans $D^k$. Faire une recherche linéaire car cette direction mène à un succès. Mettre $x^k$ à jour et recommencer. Si aucune direction de descente est trouvée, un minimum sur le maillage est atteint.
	\end{tabularx}
		\STATE \begin{tabularx}{440pt}{l X}3. & Déterminer un ensemble de points finis avec une procédure arbitraire (\SEARCH). Si cette procédure produit une diminution simple, mettre à jour la solution. Retour à 1.
		\end{tabularx}
\end{algorithmic}
\end{algorithm}
Les auteurs stipulent que le cadre algorithmique B est une adaptation du A et enchaînent avec la démonstration que la procédure répétée de A mène ultimement à un la détermination d'un point stationnaire de la fonction $f$. Ils amènent le point que l'algorithme B est beaucoup plus restreint que l'algorithme A. Par contre, c'est la routine primitive de A qui assure la convergence, malgré que le candidat entraînant la meilleure diminution n'est pas obligatoirement identifié. C'est ici qu'ils mentionnent l'opportunisme associé à ce concept algorithmique, la première instance dans littérature au meilleur de notre connaissance.
\begin{quote}
	<<Pour le cadre algorithmique A, la convergence peut être démontrée seulement pour une sous-séquences de minimum locaux du maillage. Ceci est dû au fait que la recherche effectuée à l'étape 2 est opportuniste; le premier membre rencontré dans $D$ qui donne une descente (diminution simple) mène à un nouvel itéré.>>
\end{quote}
La concept de l'opportunisme, souvent désigné autrement dans la littérature, impacte l'analyse de convergence. Dans~\cite{Torc97a}, Torczon introduit les mouvements exploratoires, sur lesquels l'analyse de convergence de \GPS, et par extension \CS, reposent. Deux résultats sont identifiés. En premier lieu, on statue que la convergence globale est assurée pour une méthode de \GPS sur une fonction objectif $f$ continue différentiable et sur un ensemble avoisinant un ensemble compacte. La conclusion étant que sous ces conditions, une série infinie d'évaluations mène à un point ou la norme du gradient est nulle.
\begin{equation}
	\label{eq:3.4}\liminf\limits_{x\rightarrow \infty}\norm{\nabla f(x_k)} = 0
\end{equation}
Ce résultat peut être renforcé par des hypothèses plus strictes sur la norme des colonnes de la matrice génératrice $Z$, sur le paramètre d'ajustement du maillage $\tau$ et, plus important encore, les hypothèses de mouvements exploratoires. Initiallement, ces hypothèses se limitaient à 
\begin{itemize}
	\item La direction $d$ est choisie $D=GZ$ et la longueur est contrôlée par $\delta^k$ 
	\item Si un des points existants dans $P^k$ entraîne une diminution simple, alors un mouvement exploratoire produira un pas qui entrainera une diminution simple.
\end{itemize}
Le résultat de convergence s'atteint en conservant la première hypothèse et en remplaçant la deuxième par la suivante : 
\begin{itemize}
	\item Si un des points existants dans $P^k$ entraîne une diminution simple, alors un mouvement exploratoire produira un pas qui entrainera la meilleure descente. 
\end{itemize}
Le résultat de convergence renforcé stipule :
\begin{equation}
	\label{eq:3.5}\lim\limits_{x\rightarrow \infty}\norm{\nabla f(x_k)} = 0.
\end{equation}
L'hypothèse sur les mouvements exploratoires est uniquement applicable si tous les points de $P^k$ sont évalués. Il en découle que la convergence est influencée par l'opportunisme. L'utilisation de la stratégie opportuniste contredit l'hypothèse nécessaire pour la convergence forte, ainsi une implémentation de \GPS opportuniste assure seulement une convergence dans le sens de la limite inférieure. Toujours dans~\cite{Torc97a}, l'auteur adapte \CS au cadre énoncé pour une méthode de \GPS, entraînant ainsi le résultat de convergence applicable à être applicable à \CS. Une situation semblable est répétée dans~\cite{KoLeTo03a} pour \GSS, soit que la convergence plus forte de l'équation (\ref{eq:3.5}) est atteignable avec la prémisse que $x^{k+1}$ soit le candidat amenant la meilleure descente seulement. 
Les algorithmes présentés dans dans la section 2 ne vont pas dans les détails de leurs implémentations et la présence de l'opportunisme y est laissée floue. Conn, Scheinberg et Vincente~\cite{CoScVibook} évoque explicitement la présence de l'opportunisme dans les cadres algorithmiques de méthodes de recherche directe directionnelles qu'ils utilisent.
\section{Ordonnancement}
L'utilisation de l'opportunisme entraîne que l'ordre des points dans l'ensemble de sonde $P^k$ prend soudainement un rôle important. Dans l'optique de réduire le nombre d'appels à la boîte noire, on s'intéresse ici à la possibilité de réordonner $P^k$ de façon à évaluer les candidats possiblement intéressants en premier lieu. Dans cet ordre d'esprit, Custodio et Vincente~\cite{CuVi07} tentent de déterminer des indicateurs de descente, c'est à dire une direction avec un potentiel de descente intéressant identifié à l'aide des informations obtenus à présent sur le problème. 
\begin{definition}[Ordonnancement]
	\label{def_ordo}L'ordonnancement réfère à la permutation des directions, soient des colonnes de $P^k$ ou $S^k$, suivant une stratégie donnée. Une stratégie guidant un ordonnancement est désignée comme stratégie d'ordonnancement.
\end{definition}
 Dans leur étude, Custodio et Vincente identifient les dérivées du simplexe, calculables à l'aide des évaluations précédentes, compte tenu de certaines contraintes sur la géométrie de l'ensemble de points choisis~\cite{CoScVi2006}. Ils utilisent la distance angulaire minimale entre $-\nabla_{s}f(x)$ et $d_i$ comme stratégie d'ordonnancement. Les résultats numériques montrent que, sur une version opportuniste de \CS, cet ordre réfléchi des points dans $P^k$ est grandement bénéfique lorsque comparé à un ordre statique, surtout si combiné à d'autre stratagèmes identifiés par les auteurs. De ces stratégies on nomme l'utilisation des informations obtenues sur chaque point (en opposition à utiliser seulement les points garantissant une diminution simple) pour assurer la répartition de l'ensemble de points ainsi que l'expansion de la longueur du pas limitée à une série de succès consécutifs issues de la même direction de succès, stratégie proposée dans~\cite{HoKoTo01a}. Custodio, Dennis et Vincente~\cite{CuDeVi08} réutilisent la stratégie dans le contexte d'optimisation non-lisse et observent toujours une amélioration en comparant avec un ordre arbitraire restant inchangé au cours de l'optimisation. Abramson, Audet et Dennis~\cite{AbAuDe04a} montrent quant à eux qu'il est possible d'élaguer l'ensemble $P^k$ de façon à n'avoir qu'une seule évaluation par étape de \POLL fructueuse en utilisant les informations sur les signes des dérivés. Lorsque Audet et Dennis introduisent \MADS~\cite{AuDe2006}, ils spécifient que l'ordre des directions dans leurs ensembles $P^k$ sont aléatoirement déterminés.  
   
Définition de précéder $\prec$

\subsection{Ordonnancement lexicographique}


\subsection{Ordonnancement en fonction du dernier succès} : =
\begin{equation}
\frac{d_{i,k}\cdot d_{i,k-1}}{||d_{i,k-1}||||{d_{i,k}||}} > \frac{d_{j,k}\cdot d_{k-1}}{||d_{k-1}||||{d_{j,k}||}}  \implies d_{i,k} \prec d_{j,k}  
\end{equation}


\subsection{Ordonnancement en fonction du modèle} : 
\begin{equation}
\tilde{f}(p_i) < \tilde{f}(p_j) \implies p_i \prec p_j
\end{equation}


\subsection{Ordonnancement aléatoire}
Hasard.\\

\subsection{Ordonnancement omniscient}
Stratégie pour tester "borne supérieure"
\begin{equation}
\tilde{f}(p_i) < \tilde{f}(p_j) \implies p_i \prec p_j
\end{equation}

\subsection{Ordonnancement négatif-omniscient}
Stratégie pour tester "borne inférieure"
\begin{equation}
\tilde{f}(p_i) < \tilde{f}(p_j) \implies p_i \prec p_j
\end{equation}

\section{Mise en place de l'opportunisme}
En forçant l'évaluation séquentielle de la fonction sur les candidats de $P^k$ et $S^k$, l'opportunisme dicte la forme à prendre pour les algorithmes. Ainsi, leurs cadres proposés dans la littérature sont raffermis et limités à des formes séquentielles. Cependant, l'application de la stratégie est limitée à certains algorithmes dont la forme permet son instauration. Certains algorithmes tels que l'algorithme de Nelder Mead~\cite{NeMe65a} et les algorithmes de régions de confiance~\cite{CoScVibook} en optimisation sans-dérivées possèdent un seul candidat par itération de l'algorithme. L'ordonnancement est donc incompatible avec certains algorithmes, ce qui justifie la tâche d'identifier préalablement un ensemble d'algorithmes compatibles. Le critère de compatible principal consiste à l'existence d'une étape ou une liste de points doit être évaluée, soient les étapes de \SEARCH et de \POLL ainsi que dans leur équivalent pour \imfil. La section qui suit détaillera la modification des étapes de \POLL pour les algorithmes de recherche directe identifiés préalablement. L'opportunisme pour les étapes de \SEARCH, quoique figurant comme paramètre pour certaines implémentations~\cite{Le09a}, est laissée de la côté pour la suite du présent travail, compte tenu de l'extrême versatilité de l'étape de \SEARCH.
\subsection{\CS, \GPS, \GSS et \MADS}
À des fins de généralité, les ensembles des directions de sonde utilisés dans \CS et dans \MADS, soient l'ensemble des directions élémentaires et $\D^k_\Delta$ seront substitués par $D^k$. 
\begin{algorithm}[H]
	\caption{\textsf{\POLL opportuniste}}
	\label{alg1}
	\begin{algorithmic}
		\STATE Avec $f:\R^n \rightarrowtail \R$ la fonction objectif et $x^0$ le point de départ
		\STATE 1. \POLL
		\bindent
		\STATE Ordonner $P^k$ selon la stratégie voulue.
		\FOR { $t \in P^k$}
		\IF {$f(t) < f(x^{k}) $}
		\STATE $x^{k+1} \leftarrow t$
		\STATE Mise à jour de $\delta^k$ et $\Delta^k$ selon un succès de l'étape
		\STATE Poursuivre à la Terminaison.
		\ENDIF
		\STATE $x^{k+1} \leftarrow x^{k}$ et $\delta^{k+1} \leftarrow \tau\delta^k$
		\STATE Mise à jour de $\delta^k$ et $\Delta^k$ selon un échec de l'étape
		\ENDFOR
		\eindent
	\end{algorithmic}
\end{algorithm}
\subsection{\imfil}
L'utilisation de l'opportunisme dans \imfil nécessite une adaptation partielle de la méthode. Premièrement, la notion de succès pour \imfil est différente de celle établie pour les autres algorithmes identifiés. On dira que la sonde du gradient comporte un succès si il existe un point $F_i$ dans $\{F\}$ pour lequel la fonction objective est simplement diminuée. Pour respecter \ref{def_ordo} sans compromis, on devrait terminer la sonde du gradient au premier succès. Cependant, \imfil enchaîne cette sonde peu raffinée avec une descente du gradient, qui constitue apporte substance à l'algorithme et lui confère un intérêt. L'interruption trop précoce de la sonde du gradient empêchera l'obtention de l'information nécessaires pour la détermination d'une direction de descente cohérente, puisque celles-ci sont déterminées à l'aide de différences finies obtenues avec les points de $F$. Par exemple, à l'obtention d'un succès à une première itération, l'algorithme effectuera une descente du gradient avec $n-1$ directions nulles. On désignera cette méthode comme \textsf{\imfil-op} pour \imfil avec opportunisme pur. On devine que cette stratégie nuira au bon fonctionnement pratique de la méthode.
\begin{algorithm}[H]
 	\caption{\textsf{Sonde du gradient \imfil-op}}
 	\label{alg5}
 	\begin{algorithmic}
 		\STATE Avec $f:\R^n \rightarrow \R$ la fonction objectif et $x^0$ le point de départ
 		\STATE Effectuer la sonde du gradient
 		\FOR {$i=1,\dots,k$}
 		\STATE $F_i = f(x^k + h^k v_i), v \in V$
 		\IF {$F_i < x^k$}
 		\STATE $x_{\min} \leftarrow F_i$
 		\STATE Poursuivre au calcul de la direction de descente
 		\ENDIF
 		\ENDFOR
 	\end{algorithmic}
\end{algorithm}

On désignera cette méthode comme \textsf{\imfil-od} pour \imfil avec opportunisme décalé. 
  
\begin{algorithm}[H]
	\caption{\textsf{Sonde du gradient \imfil-od}}
	\label{alg5}
	\begin{algorithmic}
		\STATE Avec $f:\R^n \rightarrowtail \R$ la fonction objectif et $x^0$ le point de départ
		\STATE Effectuer la sonde du gradient
		\FOR {$i=1,\dots,n$}
		\STATE $F_i = f(x^k + h^k v_i), v \in V$
		\ENDFOR
		\IF {$f(\arg \min(F)) < f(x_k)$}
		\STATE $x_{\min} \leftarrow\arg \min(F)$
		\STATE Poursuivre au calcul de la direction de descente
		\ENDIF
		\FOR {$i=n+1,\dots,k$}
		\STATE $F_i = f(x^k + h^k v_i), v \in V$
		\IF {$F_i < x^k$}
		\STATE $x_{\min} \leftarrow F_i$
		\STATE Poursuivre au calcul de la direction de descente
		\ENDIF
		\ENDFOR
	\end{algorithmic}
\end{algorithm}  
   
La méthode \textsf{\imfil-od} ===> erreur $O(h)$ plutôt que $O(h^2)$ dans le calcul de la dérivée.
\section{Modèles Quadratriques pour l'ordonnancement}
L'ordonnancement guidé par l'utilisation modèles quadratiques élaborés dans~\cite{CoLed2011} est possible avec les algorithmes présent dans NOMAD, tels que CS, GPS et MADS. Pour obtenir un modèle, on considère la base naturelle de l'espace des polynômes de degré deux et moins. 
\begin{equation*}
\xi (x)=(\xi_0(x),\xi_1(x),...,\xi_q(x))^T = \left(1,x_1,x_2,...,x_n,\frac{x_1^2}{2},\frac{x_2^2}{2},...,\frac{x_n^2}{2},x_1 x_2, x_1 x_3,...,x_{n-1},x_{n}\right)^T
\end{equation*}
Cette base possède $q+1 = (n+1)(n+2)/2$ éléments. Le modèle $m_f$ de la fonction $f$ est tel que $\tilde{f}(x)=\alpha^T\xi(x)$, $\alpha \in \R^{q+1}$. Pour obtenir ce modèle, un ensemble de point $Y=\{y^0,y^1,...,y^p\}$ ayant $p+1$ éléments est nécessaire. On cherche alors a minimiser la différence entre les valeurs de la boîte noire évaluées aux points de $Y$ et celles du modèle. Au long de l'exécution présente ou de celles passées enregistrées dans les caches, les algorithmes évalueront la boîte noire à différents points, parmis lesquels pouront être choisis les $p = q$ points nécessaires à l'élaboration du modèle. Les points devront satisfaire la propriété qui valide le modèle : 
\begin{gather*}
B(\xi,Y)\alpha = f(Y)\\
f(y)=(f(y^0,f(y^1),...,f(y^p))^T\\
B(\xi,Y) = 
\begin{bmatrix}
\xi_0(y^0) & \xi_1(y^0) & \dots & \xi_q(y^0)\\
\xi_0(y^1) & \xi_1(y^1) & \dots & \xi_q(y^1)\\
\vdots & \vdots & \vdots & \vdots\\
\xi_0(y^p) & \xi_1(y^p) & \dots & \xi_q(y^p)\\
\end{bmatrix}_.
\end{gather*}
Ce système peut être résolu seulement si $p=q$ et si la matrice est de rang pleine. Dans le cas où $p\geq q$, on tentera de résoudre le problème de minimisation suivant : 
\begin{equation*}
\begin{aligned}
& \underset{\alpha \in \R}{\text{min}}
& & \norm{B(\xi,Y)\alpha -f(Y)}^2
\end{aligned}.
\end{equation*}
Dans le cas où $p<q$, on minimisera le même problême mais en régularisant le problème à l'aide d'une interpolation dans le sense de la norme de Frobenius minimale~\cite{MoWi2009,CuRoVi10}. La norme de Frobenius pour une matrice $A$ est définie par : 
\begin{equation*}
\norm{A}_F = \sqrt{\overset{m}{\underset{i=1}{\sum}} \overset{n}{\underset{j=1}{\sum}}|a_{i,j}|}.
\end{equation*}
Il est possible de réarranger $\tilde{f}(x)$ de façon à l'illustrer comme une fonction quadratique en utilisant la notation précédente mais en divisant le modèle en ses expressions linéaires et quadratiques : 
\begin{equation*}
\tilde{f}(x) = \alpha_{L}^{T}\xi_L(x) + \alpha_{Q}^{T}\xi_Q(x).
\end{equation*}
L'indice $L$ dénote les termes linéaires et d'ordre 0 de $\xi(x)$, au compte de $n+1$, soient les $n$ variables et le terme de degré 0, $\xi_0(x)=1$. L'indice $Q$ dénote les termes quadratiques au compte de $(n+1)(n+2)/2 - (n+1) = \frac{n(n+1)}{2}$. Ainsi, on peut réecrire la quadratique en trois termes, soient le terme constant, le terme des composantes linéaires et le terme des composantes quadratiques : 
\begin{equation*}
\tilde{f}(x) = c + g^T x + \frac{1}{2} x^T H x.
\end{equation*}
Avec $g \in \R^n$ et la matrice $H\in \R^{n,n}$ la matrice Hessienne symétrique du modèle. Avec un problème sous déterminé où $p<q$, on choisira le modèle tel que :
\begin{align*}
&\underset{H \in \R^{n,n}}{\text{min}}& &\norm{H}^2_H & &\\
&\text{sujet à} & &c + g^T y^i + \frac{1}{2} (y^i)^T H (y^i) = f(y^i) & &i = 1,\dots, p.
\end{align*}
On entend ici minimiser l'influence des termes quadratiques pour diminuer l'amplitude du modèle entre les points de $Y$ utilisés. Par exemple, pour un problème de dimension $n$ avec $p\leq(n+1)$, on résoudera seulement la portion linéaire de $\alpha ^T \xi(y^i) = f(y^i)$ pour ainsi laisser $h_{i,j}=0, i,j=1\dots n$ et donc $\alpha_{Q}=0$.