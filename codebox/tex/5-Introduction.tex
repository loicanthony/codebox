%   Dans l'introduction, on présente le problème étudié et les buts
% poursuivis. L'introduction permet de faire connaître le cadre de la
% recherche et d'en préciser le domaine d'application. Elle fournit
% les précisions nécessaires en ce qui concerne le contexte de
% réalisation de la recherche, l'approche envisagée, l'évolution de
% la réalisation. En fait, l'introduction présente au lecteur ce
% qu'il doit savoir pour comprendre la recherche et en connaître la
% portée.
\Chapter{INTRODUCTION}\label{sec:Introduction}  % 10-12 lignes pour introduire le sujet.
\section{Optimisation de boîtes noires}
L'optimisation est l'étude de l'obtention d'un minimum ou d'un maximum pour un problème donné. Les problèmes sont définis par leur vecteur de variables $x$, la fonction objectif sous-jacente $f(x)$ ainsi que leur ensemble réalisable $\Omega$. On cherche alors à résoudre :
\begin{gather}
\underset{x}{\min}\{f(x)\ :\ x\ \in\ \Omega\}.
\end{gather}
avec $f : \R ^n \rightarrow \R$ et $\Omega \in R^n$. Ce problème peut prendre plusieurs formes, et plusieurs disciplines de l'optimisation existent en conséquent. Les problèmes peuvent être tels que $x$ est composé de variable continues, entières ou une combinaison des deux, pour lesquels existent l'optimisation continue, en nombres entiers et mixte. Une grande quantité de spécificités sur les variables, la fonction objectif est les contraintes mènent à une panoplie de sous-disciplines en optimisation.\\
Les principaux algorithmes d'optimisation exploitent la structure même du problème, telle la connaissance des dérivées du premier et du second degré pour la résolution. On pense ici à la méthode du simplexe pour l'optimisation linéaire~\cite{NaSo96a}, ou encore de les méthodes de Newton ou de Quasi-Newton pour l'optimisation non-linéaire~\cite{NoWr99a}.\\
Dans le cas traité dans cet ouvrage, on étudie un certain type de problème dit \textbf{boîte noire}. Les boîtes noires sont caractérisées par leur fonctionnement; elles prennent en entrée un vecteur de variables, et en ressort un résultat. Les fonctions sous-jacentes sont inconnues, trop complexes ou trop instables pour en retirer une forme analytique. On peut résumer une boîte noire à un problème complexe instable, demandant beaucoup de ressources à résoudre, dont les optima locaux sont fréquents et dont les dérivées sont inconnues, difficilement obtenables ou même inexistante. Un problème de boîte noire est en réalité l'optimisation d'une fonction qui est un boîte noire, et dont les contraintes sont aussi évaluées par des boîtes noires.\\
La discipline de l'optimisation qui se concentre sur la résolution de problèmes dont la structure de la fonction objectif et des fonctions contraintes ne peux être exploitée se nomme l'optimisation de boîte noire (\textit{BBO - Blackbox Optimization}). On distingue de cette discipline l'optimisation sans dérivées (\textit{DFO -  Derivative-free optimization}), dans laquelle on étudie la résolution de problème d'optimisation en n'utilisant aucune valeurs de dérivées de la fonction~\cite{AuHa2018,AuKok2016} Ainsi, les outils de \textit{DFO} utilisent seulement les valeurs de la fonction objectif calculées afin de bâtir des modèles qui seront eux-mêmes utilisés dans le processus d'optimisation. Contrairement à la \textit{BBO}, la \textit{DFO}  ne sous-entends pas l'inexistence des dérivées de la fonction à optimiser, seulement qu'elles ne sont peut-être pas appropriées comme outil pour la résolution du problème.\\
Conn, Scheinberg et Vincente~\cite{CoScVibook} regroupent les méthodes de \textit{DFO}  en deux familles :  les méthodes de recherche directe et les méthodes de régions de confiance. Les méthodes de recherche directe se résument à ce que d'autres nomment les méthodes d'échantillonnage (sampling methods)~\cite{Kelley2011} : l'optimisation est contrôlée par l'évaluation de $f(x)$ dans un ensemble de point, et c'est le résultat de ces évaluations qui détermine le prochain ensemble de point, jusqu'à la convergence. Les méthodes de régions de confiance, quant à elles, utilisent des modèles pour déterminer des points candidats, évaluent ces points et mettent à jour les modèles avec les résultats de ces points pour ensuite trouvé un autre point candidat et répéter ce processus jusqu'à la convergence.
\section{Définition de la problématique}
Les méthodes de recherche directe diffèrent des méthodes de régions de confiance de par leur structure. Plusieurs définitions existent pour les méthodes de recherche directe. Hooke et Jeeves~\cite{HoJe61a} proposent en 1961 une définition qui éclaircie un peu l'idée derrière les méthodes.
\begin{quote}
	On utilise l'expression «recherche directe» pour décrire l'examination séquentielle de solutions candidates impliquant la comparaison de chaque candidat à la meilleure obtenue précédemment, avec une stratégie pour déterminer les prochains candidats [...].
\end{quote}
Depuis l'avènement de problèmes dont les dérivées sont pratiquement inexistantes ou incalculables, les méthodes de recherche directe sont devenues au cœur des intérêt de plusieurs chercheurs. Cependant, puisque les évaluations sont couteuses, il y a la naissance d'un besoin de développer ces méthodes de façon à conserver leur fondements théoriques de convergence tout en ayant recours à un minimum d'évaluations de la fonction objectif. Par exemple, Audet et al.~\cite{AuIaLeDTr2014} ont travaillé à la génération d'un espace générateur avec le moins de directions possible pour ainsi réduire le nombre de directions nécessaires à chaque itération.
À chaque itération, un algorithme de recherche directe possède une liste d'au moins un point candidat, tandis qu'un algorithme de régions de confiance n'en a assurément qu'un seul. Certaines méthode de recherche directe sont cependant similaires aux méthodes de régions de confiance en ce sens, tel que l'algorithme de Nelder Mead~\cite{NeMe65a}, qui est classée comme une méthode de recherche directe simpliciale par Conn, Scheinberg et Vincente~\cite{CoScVibook}.\\
Puisque chaque évaluation de la fonction objectif est très couteuse en ressources, on en vient à se demander l'évaluation de chaque point dans la liste générée à chaque itération est nécessaire au bon déroulement de l'algorithme. Torczon~\cite{Torc97a} démontre qu'une famille d'algorithme de recherche directe converge vers un optimum sans avoir à évaluer tous les points dans une liste générée à une itération donnée. Ainsi, la convergence n'est pas assurée par la qualité de la direction de descente utilisée à chaque itération $f(x^k+\delta^k d) = \min(f(x^k+\delta^k d:d\in D)) $ , mais par sa propriété de répondre à la définition de décroissance simple $f(x^k+\delta^k d)~-~f(x^k)~<~0$, avec $\delta^k$ la longueur du pas et $d \in D^k $ la direction de descente choisie dans l'ensemble des directions $D$, pour l'itération $k$. On en vient à l'élaboration d'une problématique qui justifie le projet. Pour un algorithme possédant à l'itération $k$ une solution courante $x_k$ et un liste de candidat $P^k$, on cherche à déterminer si la découverte d'un nouveau meilleur point dans cette liste devrait entrainer un passage prématuré à l'itération suivante de l'algorithme.\\
\section{Objectif de la recherche}
Le long de ce mémoire, l'interruption prématurée d'une étape nécessaire à la convergence d'un algorithme sera nommée \textit{stratégie opportuniste} ou \textit{opportunisme}, de l'expression pour référer à cette nomenclature introduite par Coope et Price~\cite{CoPr01a} et reprise par Audet et Dennis~\cite{AuDe04a}. La question restant très vague, on devra définir plusieurs aspects afin d'en venir à une quantification de l'impact de l'opportunisme sur le déroulement d'algorithmes de \textit{DFO}.\\
En premier lieu, la structure de l'algorithme doit admettre qu'au cours d'une itération il existe une liste de point à évaluer séquentiellement avant la détermination d'une autre liste de points. Ainsi, appartenir à la famille des méthodes de recherche directe n'est pas un critère suffisant compte tenu que l'algorithme de Nelder Mead y figure, malgré qu'il évalue un point à la fois. Cependant, d'autres famille d'algorithmes ouvrent la porte à l'opportunisme par leur fabrication. Notons ici les méthodes de recherche linéaire basée sur les dérivées simplexe, telles que baptisées par Conn, Scheinberg and Vincente~\cite{CoScVibook}, qui ne concordent pas exactement à la définition de méthodes de recherche directe. Un objectif premier de cette recherche est d'identifier les algorithmes laissant place à l'implémentation de l'opportunisme en eux.\\
De l'utilisation de l'opportunisme apparait une autre problématique au coeur de cette recherche, c'est à dire la stratégie utilisée pour ordonner les points candidats dans la liste. Si on permet une interruption de la séquence d'évaluation des points sur la liste lors de l'obtention d'un meilleur point, alors l'ordre dans laquelle apparaît ces points sera au cœur du comportement de l'algorithme. On nommera la règle définissant l'ordre des points dans la liste la \textit{stratégie d'ordonnancement}. Le second objectif de cette recherche est d'identifier les stratégies d'ordonnancement qui pourraient avoir un impact sur la performance de la stratégie opportuniste.\\
Ayant en main un éventail d'algorithmes et de stratégies d'ordonnancement, on pourra procéder à l'objectif principal de la recherche, soit la quantification de la performance de l'utilisation de la stratégie opportuniste dans les algorithmes, ainsi que la comparaison des différentes stratégies d'ordonnancement identifiées. On cherche ainsi à déterminer les cas dans lesquels l'opportunisme est une stratégie envisageable, nécessaire, ou contraignante. On cherche aussi à caractériser les différentes stratégies d'ordonnancement en fonction du type de problème à résoudre, des spécificités algorithmiques ou en fonction de la précision demandée à l'algorithme. 
\section{Plan du mémoire}
